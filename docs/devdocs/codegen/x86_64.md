# Phase A Codegen Quickstart (x86-64 SysV)

## ABI snapshot

- **Calling convention:** System V AMD64.
- **Argument passing:**
    - Integer/pointer: RDI, RSI, RDX, RCX, R8, R9 then stack (8-byte slots).
    - Floating-point: XMM0–XMM7 then stack (16-byte shadow per spill).
    - Structs up to 16 bytes split across GPR/SIMD per ABI classes; larger by pointer.
- **Register preservation:**
    - Callee-saved: RBX, RBP, R12–R15 (plus stack pointer RSP). Preserve XMM callee-saves only if ABI extension
      requires (Phase A: none).
    - Caller-saved: RAX, RCX, RDX, RSI, RDI, R8–R11, XMM0–XMM15.
- **Return values:**
    - Aggregates >128 bits: caller allocates and passes pointer in RDI; callee writes there.
    - Float/vector in XMM0 (XMM1 if second part).
    - Integer/pointer/scalar ≤64 bits in RAX (plus RDX if >64 bits but ≤128).

## i1 lowering policy

- Memory slots for `i1` still occupy 1 byte; extend on load, truncate on store.
- On calls/returns, widen to full 8-byte slot (zero-extend) before passing or returning.
- Represent boolean SSA values as 0/1 in 64-bit GPRs.

## Stack discipline

- Maintain 16-byte alignment at every call boundary. Adjust prologue to align `RSP` after pushing the return address.
- Spill slots allocated in 16-byte multiples when mixing SIMD/GPR spills; pure GPR spills may use 8-byte stride, but
  ensure call sites realign.

## Block parameters to ParallelCopy

- IL block parameters become edge-specific ParallelCopy bundles in MIR. Each CFG edge owns one copy list executed before
  the successor block executes.
- Ensure φ-like moves are ordered with ParallelCopy to avoid clobbers; insert temps when cycles exist.
- The resolver lives at `src/codegen/common/ParallelCopyResolver.hpp` (target-independent); the x86-64-specific
  forwarding header is at `src/codegen/x86_64/ParallelCopyResolver.hpp`.

## Phase A scope

- Implements instruction selection to MIR, linear scan register allocation, frame layout, and textual assembly
  emission (`asmText`).
- Defers: stack-based argument expansion beyond simple scalars, vector ABI oddities (mask regs, varargs), shrink
  wrapping, pro/epilogue peepholes, ELF emission, debug info.

## Phase A completeness

- [x] Call-site alignment checks enforcing 16-byte `RSP` invariants.
- [x] f64 constant materialization through literal pools or inline immediates.
- [x] Return moves handled via tail ParallelCopy folding.
- [x] `select` lowering for GPR and f64 operands.
- [x] Shift family (`shl`, `lshr`, `ashr`) mapped to x86-64 semantics.
- [x] String literal plumbing from IL globals through data segments.

## Operation notes

- **Bitwise ops:** `LowerILToMIR` selects `AND`/`OR`/`XOR` for both register-register and register-immediate forms
  (see `src/codegen/x86_64/Lowering.Bitwise.cpp`).
- **Overflow-checked arithmetic:** `LowerOvf.cpp` expands overflow-checked arithmetic pseudos into guarded sequences.
- **Signed & unsigned div/rem:** `LowerDiv.cpp` expands MIR pseudos into guarded `idiv`/`div` sequences and emits
  `rt_trap_div0` calls when the divisor is zero.

## Adding a new opcode

1. Introduce the MIR opcode in `src/codegen/x86_64/MachineIR.hpp`/`.cpp`, documenting operands, result class, and
   verifier hooks.
   Update any helpers or enumerations that surface the opcode to the rest of the backend.
2. Extend IL → MIR selection in `src/codegen/x86_64/LowerILToMIR.hpp`/`.cpp` (and the relevant `Lowering.*.cpp`
   specialization files; add a focused matcher in `ISel.hpp`/`.cpp` if needed).
   Keep selection predicates narrow so unrelated patterns are unaffected.
3. Map the opcode to a physical mnemonic inside `src/codegen/x86_64/AsmEmitter.hpp`/`.cpp`, keeping operand ordering
   consistent.
   Verify operand modifiers (e.g., `byte ptr`) match the intended encoding.
4. Update lowering helpers or post-processing passes (e.g., `LowerDiv.cpp` for div/rem, `LowerOvf.cpp` for overflow
   ops) if the opcode needs multi-instruction support.
5. Update the selection tests (e.g., `src/tests/codegen/x86_64/*`) with a focused case that exercises the new path
   end-to-end.
   Aim for a MIR dump and final assembly snippet to catch regressions early.
6. Regenerate or adjust any MIR/assembly golden files touched by the opcode, keeping Phase A invariants intact.
   Confirm stack alignment assertions still pass under `ctest`.

## Source file map

### Core backend

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/Backend.hpp`/`.cpp` | Top-level facade; orchestrates `runFunctionPipeline` and `emitModuleImpl` |
| `src/codegen/x86_64/MachineIR.hpp`/`.cpp` | MIR data structures (`MFunction`, `MBasicBlock`, `MInstr`, `MOpcode`) |
| `src/codegen/x86_64/TargetX64.hpp`/`.cpp` | Physical register enum, `TargetInfo` singleton (`hostTarget()`), ABI helpers |

### Lowering

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/LowerILToMIR.hpp`/`.cpp` | IL → MIR translation; call plan capture |
| `src/codegen/x86_64/LoweringRules.hpp`/`.cpp` | Lowering rule dispatch table |
| `src/codegen/x86_64/LoweringRuleTable.hpp`/`.cpp` | Rule table data |
| `src/codegen/x86_64/Lowering.Arith.cpp` | Arithmetic instruction lowering |
| `src/codegen/x86_64/Lowering.Bitwise.cpp` | Bitwise instruction lowering |
| `src/codegen/x86_64/Lowering.CF.cpp` | Control-flow instruction lowering |
| `src/codegen/x86_64/Lowering.EH.cpp` | Exception-handling instruction lowering |
| `src/codegen/x86_64/Lowering.EmitCommon.hpp`/`.cpp` | Shared lowering helpers (SELECT, FP constants, etc.) |
| `src/codegen/x86_64/Lowering.Mem.cpp` | Memory instruction lowering (load, store, alloca, gep) |
| `src/codegen/x86_64/CallLowering.hpp`/`.cpp` | Call ABI: argument marshalling, outgoing stack setup |
| `src/codegen/x86_64/ISel.hpp`/`.cpp` | Instruction selection: canonicalize MIR pseudos into concrete x86-64 ops |
| `src/codegen/x86_64/LowerDiv.cpp` | Signed/unsigned div/rem → `CQO`/`IDIV`/`DIV` with zero-check trap |
| `src/codegen/x86_64/LowerOvf.cpp` | Overflow-checked arithmetic → guarded sequences |

### Register allocation

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/RegAllocLinear.hpp`/`.cpp` | Entry point (`allocate()`); linear-scan core |
| `src/codegen/x86_64/ra/Allocator.hpp`/`.cpp` | Allocation loop, spill victim selection (Belady heuristic) |
| `src/codegen/x86_64/ra/Coalescer.hpp`/`.cpp` | Copy coalescing to reduce redundant moves |
| `src/codegen/x86_64/ra/LiveIntervals.hpp`/`.cpp` | Live interval computation (`kInvalidVReg = UINT16_MAX` sentinel) |
| `src/codegen/x86_64/ra/Spiller.hpp`/`.cpp` | Spill/reload insertion (`kSpillSlotOffset = 1000` separates alloca from spill slots) |

### Frame and emission

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/AsmEmitter.hpp`/`.cpp` | AT&T assembly emission; `RoDataPool` for string/FP constants |
| `src/codegen/x86_64/FrameLowering.hpp`/`.cpp` | Prologue/epilogue insertion, spill slot assignment |
| `src/codegen/x86_64/Peephole.hpp`/`.cpp` | Post-RA peephole optimizations; returns `std::size_t` transformation count |
| `src/codegen/x86_64/asmfmt/Format.hpp`/`.cpp` | Label sanitization, assembly formatting utilities |
| `src/codegen/x86_64/Unsupported.hpp` | Helper for unimplemented opcode error reporting |
| `src/codegen/x86_64/OperandUtils.hpp` | Alignment and operand utility functions |
| `src/codegen/x86_64/ParallelCopyResolver.hpp` | Forwarding header to `common/ParallelCopyResolver.hpp` |
| `src/codegen/x86_64/generated/EncodingTable.inc` | Generated opcode encoding table |
| `src/codegen/x86_64/generated/OpFmtTable.inc` | Generated operand format table |

### Pipeline passes (in `passes/` subdirectory)

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/passes/PassManager.hpp`/`.cpp` | x86-64 `Module` state struct; aliases to common `PassManager<Module>` |
| `src/codegen/x86_64/passes/LoweringPass.hpp`/`.cpp` | Pass: IL → adapter IL lowering |
| `src/codegen/x86_64/passes/LegalizePass.hpp`/`.cpp` | Pass: legalization (stub; real work in EmitPass) |
| `src/codegen/x86_64/passes/RegAllocPass.hpp`/`.cpp` | Pass: register allocation (stub; real work in EmitPass) |
| `src/codegen/x86_64/passes/EmitPass.hpp`/`.cpp` | Pass: MIR emission and backend pipeline orchestration |

### Pipeline orchestration

| File | Purpose |
|------|---------|
| `src/codegen/x86_64/CodegenPipeline.hpp`/`.cpp` | High-level driver: loads IL, runs passes, links native output |

### Common library (`src/codegen/common/`)

| File | Purpose |
|------|---------|
| `src/codegen/common/Diagnostics.hpp`/`.cpp` | Diagnostic sink for pass errors and warnings |
| `src/codegen/common/LabelUtil.hpp` | Assembler-safe label sanitization (hyphens → underscores) |
| `src/codegen/common/LinkerSupport.hpp`/`.cpp` | Shared linker invocation, build-dir management, archive selection |
| `src/codegen/common/ParallelCopyResolver.hpp` | Target-independent parallel-copy resolution (φ-elimination) |
| `src/codegen/common/PassManager.hpp` | Generic `Pass<M>` and `PassManager<M>` templates |
| `src/codegen/common/RuntimeComponents.hpp` | Runtime component classification for selective linking |
| `src/codegen/common/TargetInfoBase.hpp` | Shared base for `TargetInfo` structs |

## Backend pipeline map

1. **IL to MIR lowering** (`LowerILToMIR::lower`, `LowerILToMIR.hpp`/`.cpp` + `Lowering.*.cpp` files): pattern-match
   IL ops to target MIR. Add new opcode translations here.
2. **Call lowering** (`CallLowering.hpp`/`.cpp`, invoked from `lowerPendingCalls` in `Backend.cpp`): expand CALL
   placeholders into argument-marshalling sequences.
3. **Instruction selection** (`ISel.hpp`/`.cpp`): rewrite generic MIR pseudos into target-specific ops
   (arith/compare/select).
4. **Division expansion** (`LowerDiv.cpp`): rewrite signed/unsigned div/rem pseudos into guarded IDIV/DIV sequences.
5. **Overflow expansion** (`LowerOvf.cpp`): rewrite overflow-checked arithmetic pseudos into guarded sequences.
6. **Parallel copy resolution** (`ParallelCopyResolver.hpp`): expand block parameter moves into ordered copies during
   lowering.
7. **Register allocation** (`RegAllocLinear.hpp`/`.cpp`, `ra/Allocator.cpp`, `ra/Coalescer.cpp`, `ra/Spiller.cpp`):
   map virtual regs to physical; insert spills/reloads.
8. **Frame/stack planning** (`FrameLowering.hpp`/`.cpp`): assign spill slots and emit prologue/epilogue.
9. **Post-RA cleanup** (`Peephole.hpp`/`.cpp`): peephole optimizations applied after register allocation; returns
   number of transformations applied.
10. **Emitter** (`AsmEmitter.hpp`/`.cpp`): produce final assembly text and manage rodata pools.

- To add a new lowering pass, slot it before RA if it rewrites SSA, after RA otherwise; update `Backend.cpp`'s
  `runFunctionPipeline` to invoke it.

## Debugging checklist

- Check MIR output at each pipeline stage to trace lowering/allocation decisions.
- Inspect emitted assembly by reading `asmText` from the compiled function object.
- Use targeted `dbg()` prints inside lowering stages; guard them with compile-time flags to keep release builds quiet.
