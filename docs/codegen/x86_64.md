# Phase A Codegen Quickstart (x86-64 SysV)

## ABI snapshot
- **Calling convention:** System V AMD64.
- **Argument passing:**
  - Integer/pointer: RDI, RSI, RDX, RCX, R8, R9 then stack (8-byte slots).
  - Floating-point: XMM0–XMM7 then stack (16-byte shadow per spill).
  - Structs up to 16 bytes split across GPR/SIMD per ABI classes; larger by pointer.
- **Return values:**
  - Integer/pointer/scalar ≤64 bits in RAX (plus RDX if >64 bits but ≤128).
  - Float/vector in XMM0 (XMM1 if second part).
  - Aggregates >128 bits: caller allocates and passes pointer in RDI; callee writes there.
- **Register preservation:**
  - Caller-saved: RAX, RCX, RDX, RSI, RDI, R8–R11, XMM0–XMM15.
  - Callee-saved: RBX, RBP, R12–R15 (plus stack pointer RSP). Preserve XMM callee-saves only if ABI extension requires (Phase A: none).

## i1 lowering policy
- Represent boolean SSA values as 0/1 in 64-bit GPRs.
- On calls/returns, widen to full 8-byte slot (zero-extend) before passing or returning.
- Memory slots for `i1` still occupy 1 byte; extend on load, truncate on store.

## Stack discipline
- Maintain 16-byte alignment at every call boundary. Adjust prologue to align `RSP` after pushing the return address.
- Spill slots allocated in 16-byte multiples when mixing SIMD/GPR spills; pure GPR spills may use 8-byte stride, but ensure call sites realign.

## Block parameters to ParallelCopy
- IL block parameters become edge-specific ParallelCopy bundles in MIR. Each CFG edge owns one copy list executed before the successor block executes.
- Ensure φ-like moves are ordered with ParallelCopy to avoid clobbers; insert temps when cycles exist.

## Phase A scope
- Implements instruction selection to MIR, linear scan register allocation, frame layout, and textual assembly emission (`asmText`).
- Defers: stack-based argument expansion beyond simple scalars, vector ABI oddities (mask regs, varargs), shrink wrapping, pro/epilogue peepholes, ELF emission, debug info.

## Backend pipeline map
1. **IL to MIR lowering** (`lowerIlFunction`): pattern-match IL ops to target MIR. Add new opcode translations here.
2. **SSA utilities** (`buildParallelCopies`, `fixPhiEdges`): handle block params → ParallelCopy. Extend when new SSA forms appear.
3. **Frame/stack planning** (`assignFrameSlots`, `finalizePrologueEpilogue`): choose spill slots, align stack.
4. **Register allocation** (`linearScan`): map virtual regs to physical; insert spills/reloads.
5. **Post-RA cleanup & peepholes** (`runPeepholes`, `simplifyCopies`): optional; ensure `--enable-peepholes` flag controls extras.
6. **Emitter** (`emitAsmText`): produce final text; consult this when debugging.
- To add a new lowering pass, slot it before RA if it rewrites SSA, after RA otherwise; update `runBackendPipeline` to invoke it.

## Debugging checklist
- Inspect emitted assembly with `--dump-asm` or by reading `asmText` from the compiled function object.
- Enable peephole optimizations (`--enable-peepholes`) to catch missed canonicalizations.
- Build with `VIPER_MIR_DEBUG=1` (or equivalent flag) to dump intermediate MIR, including ParallelCopies and allocation decisions.
- Use targeted `dbg()` prints inside lowering stages; guard them with compile-time flags to keep release builds quiet.

